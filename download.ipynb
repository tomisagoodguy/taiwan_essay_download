{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61b4bfba",
   "metadata": {},
   "source": [
    "============================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea65d1d0",
   "metadata": {},
   "source": [
    "除錯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e6eba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "import zipfile\n",
    "import shutil\n",
    "import math\n",
    "from typing import List, Set, Optional, Tuple\n",
    "from urllib.parse import quote\n",
    "\n",
    "import ddddocr\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.remote.webelement import WebElement\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.common.exceptions import (\n",
    "    NoSuchElementException,\n",
    "    TimeoutException,\n",
    "    UnexpectedAlertPresentException,\n",
    "    NoAlertPresentException,\n",
    "    WebDriverException\n",
    ")\n",
    "\n",
    "# 獲取腳本所在的目錄，確保所有檔案路徑都是相對於腳本位置的\n",
    "BASE_DIR = os.path.dirname(os.path.abspath(\n",
    "    __file__)) if '__file__' in locals() else os.getcwd()\n",
    "\n",
    "\n",
    "class BaseThesisDownloader:\n",
    "    \"\"\"\n",
    "    臺灣博碩士論文網自動下載器 - 基礎類別 (v4 邏輯)。\n",
    "    這個基礎類別包含了所有核心的爬取、解析和下載邏輯。\n",
    "    \"\"\"\n",
    "    # ... (此基礎類別的程式碼與前一版本完全相同，此處為節省篇幅省略)\n",
    "    # ... (為了保持完整性，在下面的最終程式碼區塊中會包含全部內容)\n",
    "    def __init__(self,\n",
    "                 keyword: str,\n",
    "                 download_dir: str = \"downloaded_theses\",\n",
    "                 log_file: str = \"download_log.txt\",\n",
    "                 page_progress_file: str = \"page_progress.txt\",\n",
    "                 max_downloads_per_session: int = 70,\n",
    "                 items_per_page: int = 10,\n",
    "                 inter_article_sleep_range: Tuple[float, float] = (10.0, 20.0),\n",
    "                 inter_page_sleep_range: Tuple[float, float] = (20.0, 45.0)\n",
    "                 ):\n",
    "        self.base_url = \"https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/login?o=dwebmge\"\n",
    "        self.keyword = keyword\n",
    "        self.download_dir = os.path.join(BASE_DIR, download_dir)\n",
    "        self.log_file = os.path.join(BASE_DIR, log_file)\n",
    "        self.page_progress_file = os.path.join(BASE_DIR, page_progress_file)\n",
    "        self.max_downloads_per_session = max_downloads_per_session\n",
    "        self.items_per_page = items_per_page\n",
    "        self.inter_article_sleep_range = inter_article_sleep_range\n",
    "        self.inter_page_sleep_range = inter_page_sleep_range\n",
    "        self.downloaded_urls, self.last_crawled_page = self._load_log()\n",
    "        self.session_download_count = 0\n",
    "        self.total_pages = 0\n",
    "        self.driver: Optional[webdriver.Chrome] = None\n",
    "        self.wait: Optional[WebDriverWait] = None\n",
    "        self.main_window_handle: Optional[str] = None\n",
    "        print(\"[-] 正在初始化 ddddocr 引擎...\")\n",
    "        self.ocr = ddddocr.DdddOcr(show_ad=False)\n",
    "        print(\"[*] ddddocr 引擎初始化完成。\")\n",
    "        print(f\"[*] 本次執行最大下載量設定為: {self.max_downloads_per_session} 篇\")\n",
    "        print(f\"[*] 文章間延遲範圍: {self.inter_article_sleep_range} 秒\")\n",
    "        print(f\"[*] 翻頁間延遲範圍: {self.inter_page_sleep_range} 秒\")\n",
    "\n",
    "    def _normalize_url(self, url: str) -> Optional[str]:\n",
    "        if not isinstance(url, str): return None\n",
    "        match = re.search(r'/record\\?.*$', url)\n",
    "        return match.group(0) if match else None\n",
    "\n",
    "    def _setup_driver(self):\n",
    "        print(\"[-] 設定 Selenium WebDriver...\")\n",
    "        os.makedirs(self.download_dir, exist_ok=True)\n",
    "        print(f\"[*] 所有 PDF 將會下載至: {self.download_dir}\")\n",
    "        chrome_options = Options()\n",
    "        prefs = {\n",
    "            \"download.default_directory\": self.download_dir, \"download.prompt_for_download\": False,\n",
    "            \"download.directory_upgrade\": True, \"plugins.always_open_pdf_externally\": True\n",
    "        }\n",
    "        chrome_options.add_experimental_option(\"prefs\", prefs)\n",
    "        chrome_options.add_argument(\"--no-sandbox\")\n",
    "        chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        chrome_options.add_argument(\"--disable-gpu\")\n",
    "        chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "        chrome_options.add_argument(\"--disable-popup-blocking\")\n",
    "        chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "        try:\n",
    "            service = Service(ChromeDriverManager().install())\n",
    "            self.driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "        except Exception as e:\n",
    "            print(f\"[錯誤] WebDriver 初始化失敗: {e}\")\n",
    "            raise\n",
    "        self.wait = WebDriverWait(self.driver, 20)\n",
    "\n",
    "    def _load_log(self) -> Tuple[Set[str], int]:\n",
    "        urls, last_page = set(), 1\n",
    "        try:\n",
    "            with open(self.log_file, 'r', encoding='utf-8') as f:\n",
    "                urls = {self._normalize_url(line.strip()) for line in f if line.strip() and self._normalize_url(line.strip())}\n",
    "            print(f\"[*] 已從 {self.log_file} 載入 {len(urls)} 筆有效紀錄。\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"[*] 未找到下載紀錄檔 {self.log_file}，將會從頭開始下載。\")\n",
    "        try:\n",
    "            with open(self.page_progress_file, 'r', encoding='utf-8') as f:\n",
    "                content = f.read().strip()\n",
    "                if content.isdigit():\n",
    "                    last_page = int(content)\n",
    "                    print(f\"[*] 已從 {self.page_progress_file} 載入上次爬取進度：從第 {last_page} 頁開始。\")\n",
    "                else:\n",
    "                    print(f\"[*] {self.page_progress_file} 內容無效，將從第 1 頁開始。\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"[*] 未找到頁數進度檔 {self.page_progress_file}，將從第 1 頁開始。\")\n",
    "        return urls, last_page\n",
    "\n",
    "    def _log_download(self, url: str):\n",
    "        normalized_url = self._normalize_url(url)\n",
    "        if not normalized_url:\n",
    "            print(f\"[警告] 無法正規化此 URL，將不予記錄: {url}\")\n",
    "            return\n",
    "        with open(self.log_file, 'a', encoding='utf-8') as f: f.write(normalized_url + '\\n')\n",
    "        self.downloaded_urls.add(normalized_url)\n",
    "        self.session_download_count += 1\n",
    "        print(f\"      - [計數] 本次執行已下載 {self.session_download_count}/{self.max_downloads_per_session} 篇。\")\n",
    "\n",
    "    def _log_progress(self, page_num: int):\n",
    "        try:\n",
    "            with open(self.page_progress_file, 'w', encoding='utf-8') as f: f.write(str(page_num))\n",
    "            print(f\"[*] 已記錄頁數進度：第 {page_num} 頁。\")\n",
    "        except Exception as e: print(f\"[錯誤] 記錄頁數進度時發生錯誤: {e}\")\n",
    "\n",
    "    def wait_for_manual_login(self):\n",
    "        print(\"\\n[步驟 1] 等待使用者手動登入...\")\n",
    "        self.driver.get(self.base_url)\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"★★★ 請手動操作瀏覽器 ★★★\")\n",
    "        print(\"程式已開啟網站首頁，請在瀏覽器視窗中手動完成所有登入步驟。\")\n",
    "        print(\"程式將會自動偵測登入狀態，成功登入後會自動繼續...\")\n",
    "        print(\"=\"*50 + \"\\n\")\n",
    "        try:\n",
    "            self.wait.until(EC.presence_of_element_located((By.XPATH, \"//div[@class='user_area']//a[text()='登出']\")))\n",
    "            print(\"[*] 偵測到「登出」按鈕，確認使用者已登入。\")\n",
    "        except TimeoutException: raise Exception(\"手動登入逾時（未能偵測到「登出」按鈕）。請確保您已成功登入。\")\n",
    "\n",
    "    def run_search(self):\n",
    "        print(\"\\n[步驟 2] 執行關鍵字搜尋...\")\n",
    "        self.driver.get(\"https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd=20_UgG/search?mode=basic\")\n",
    "        try:\n",
    "            search_box = self.wait.until(EC.presence_of_element_located((By.ID, \"ysearchinput0\")))\n",
    "            search_box.send_keys(self.keyword)\n",
    "            search_button = self.wait.until(EC.element_to_be_clickable((By.ID, \"gs32search\")))\n",
    "            search_button.click()\n",
    "            print(f\"[*] 已成功提交搜尋，關鍵字為: '{self.keyword}'\")\n",
    "            try:\n",
    "                print(\"[-] 正在等待總筆數資訊載入...\")\n",
    "                summary_container = self.wait.until(EC.visibility_of_element_located((By.XPATH, \"//td[@headers='start' and contains(., '檢索結果共')]\")))\n",
    "                match = re.search(r'檢索結果共\\s*(\\d+)\\s*筆資料', summary_container.text)\n",
    "                if match:\n",
    "                    total_items = int(match.group(1))\n",
    "                    self.total_pages = math.ceil(total_items / self.items_per_page)\n",
    "                    print(f\"[*] (全新方法) 成功解析總筆數: {total_items} 筆，計算出總頁數: {self.total_pages} 頁。\")\n",
    "                else: raise NoSuchElementException(\"無法從摘要文字中用 RegEx 解析總筆數\")\n",
    "            except (NoSuchElementException, TimeoutException):\n",
    "                print(\"[警告] 未能成功解析到明確的總筆數，將使用「下一頁」按鈕判斷結束。\")\n",
    "                self.total_pages = 0\n",
    "            page_to_start = self.last_crawled_page\n",
    "            if page_to_start > 1:\n",
    "                if self.total_pages > 0 and page_to_start <= self.total_pages:\n",
    "                    print(f\"[*] 嘗試跳轉到上次中斷的第 {page_to_start} 頁...\")\n",
    "                    try:\n",
    "                        jmpage_input = self.wait.until(EC.visibility_of_element_located((By.ID, \"jmpage\")))\n",
    "                        self.driver.execute_script(\"arguments[0].value = arguments[1];\", jmpage_input, str(page_to_start))\n",
    "                        jump_button = self.wait.until(EC.element_to_be_clickable((By.NAME, \"jumpfmt1page\")))\n",
    "                        old_page_element = self.driver.find_element(By.TAG_NAME, 'html')\n",
    "                        jump_button.click()\n",
    "                        self.wait.until(EC.staleness_of(old_page_element))\n",
    "                        print(f\"[*] 成功跳轉到第 {page_to_start} 頁。\")\n",
    "                        time.sleep(random.uniform(2.0, 4.0))\n",
    "                    except Exception as e:\n",
    "                        print(f\"[錯誤] 跳轉頁面時發生錯誤: {e}，將從第 1 頁開始爬取。\")\n",
    "                        self.last_crawled_page = 1\n",
    "                else:\n",
    "                    print(f\"[*] 上次頁數 ({page_to_start}) 無效或總頁數未知，將從頭開始。\")\n",
    "                    self.last_crawled_page = 1\n",
    "        except TimeoutException:\n",
    "            print(\"[錯誤] 搜尋頁面元素載入逾時。\")\n",
    "            self.driver.save_screenshot(\"search_page_timeout.png\")\n",
    "            raise\n",
    "\n",
    "    def _sanitize_filename(self, name: str) -> str:\n",
    "        sanitized_name = re.sub(r'[\\\\/*?:\"<>|]', \"\", name)\n",
    "        sanitized_name = re.sub(r'[\\n\\t\\r]', \" \", sanitized_name)\n",
    "        sanitized_name = re.sub(r'\\s+', \" \", sanitized_name).strip()\n",
    "        max_len = 150\n",
    "        return sanitized_name[:max_len].strip() if len(sanitized_name) > max_len else sanitized_name\n",
    "\n",
    "    def _parse_article_links(self) -> List[Tuple[str, str]]:\n",
    "        results = []\n",
    "        try:\n",
    "            self.wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"td.tdfmt1-content\")))\n",
    "            article_elements = self.driver.find_elements(By.CSS_SELECTOR, \"td.tdfmt1-content\")\n",
    "            for elem in article_elements:\n",
    "                try:\n",
    "                    elem_text = elem.text\n",
    "                    is_embargoed = \"網際網路公開日期\" in elem_text\n",
    "                    is_ip_restricted = \"校內系統及IP範圍內開放\" in elem_text\n",
    "                    if is_embargoed or is_ip_restricted:\n",
    "                        try:\n",
    "                            title_for_log = elem.find_element(By.CSS_SELECTOR, \"span.etd_d\").text\n",
    "                            reason = \"論文尚未公開 (Embargo)\" if is_embargoed else \"論文限校內IP (IP Restricted)\"\n",
    "                            print(f\"    - [跳過] {reason}: {title_for_log}\")\n",
    "                        except NoSuchElementException: print(\"    - [跳過] 發現一篇無法立即下載的論文。\")\n",
    "                        continue\n",
    "                    link_tag = elem.find_element(By.CSS_SELECTOR, \"a.slink\")\n",
    "                    title_span = link_tag.find_element(By.CSS_SELECTOR, \"span.etd_d\")\n",
    "                    url = link_tag.get_attribute('href')\n",
    "                    title = title_span.text\n",
    "                    if url and title: results.append((url, title))\n",
    "                except NoSuchElementException: continue\n",
    "            if not results: print(\"[提示] 本頁未找到任何有效的論文連結 (a.slink)。\")\n",
    "        except TimeoutException: print(\"[警告] 等待論文連結載入逾時。\")\n",
    "        return results\n",
    "\n",
    "    def _wait_for_download_complete(self, timeout: int = 180) -> Optional[str]:\n",
    "        print(\"      - 自動監控下載中...\", end=\"\")\n",
    "        seconds, initial_dl_files = 0, set(os.listdir(self.download_dir))\n",
    "        while seconds < timeout:\n",
    "            new_files = set(os.listdir(self.download_dir)) - initial_dl_files\n",
    "            if new_files:\n",
    "                new_file_name = new_files.pop()\n",
    "                if not new_file_name.endswith('.crdownload'):\n",
    "                    full_path = os.path.join(self.download_dir, new_file_name)\n",
    "                    try:\n",
    "                        with open(full_path, 'rb'): pass\n",
    "                        print(f\" 下載完成: {new_file_name}\")\n",
    "                        return full_path\n",
    "                    except IOError: pass\n",
    "            time.sleep(1)\n",
    "            seconds += 1\n",
    "            if seconds % 10 == 0: print(\".\", end=\"\", flush=True)\n",
    "        print(\"\\n      - [錯誤] 等待下載逾時。\")\n",
    "        return None\n",
    "\n",
    "    def _preprocess_captcha_image(self, image_bytes: bytes) -> bytes:\n",
    "        try:\n",
    "            img = Image.open(BytesIO(image_bytes)).convert('L').point(lambda p: 255 if p > 128 else 0)\n",
    "            buffered = BytesIO()\n",
    "            img.save(buffered, format=\"PNG\")\n",
    "            return buffered.getvalue()\n",
    "        except Exception as e:\n",
    "            print(f\"      - [警告] 驗證碼圖片預處理失敗: {e}\")\n",
    "            return image_bytes\n",
    "\n",
    "    def _solve_captcha_with_ddddocr(self, captcha_element: WebElement) -> str:\n",
    "        try:\n",
    "            res = self.ocr.classification(self._preprocess_captcha_image(captcha_element.screenshot_as_png))\n",
    "            res_cleaned = ''.join(filter(str.isalnum, res)).lower()\n",
    "            print(f\"      - ddddocr 辨識結果: '{res}' -> 清理後: '{res_cleaned}'\")\n",
    "            if 4 <= len(res_cleaned) <= 6: return res_cleaned\n",
    "            return \"\"\n",
    "        except Exception as e:\n",
    "            print(f\"      - [錯誤] ddddocr 處理過程中發生錯誤: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def _unzip_and_cleanup(self, file_path: str, new_name_base: str):\n",
    "        if not file_path.lower().endswith('.zip'): return\n",
    "        new_pdf_name, dest_pdf_path = f\"{new_name_base}.pdf\", os.path.join(self.download_dir, f\"{new_name_base}.pdf\")\n",
    "        print(f\"      - 正在解壓縮並重新命名為: {new_pdf_name}\")\n",
    "        try:\n",
    "            with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "                pdf_files_in_zip = [name for name in zip_ref.namelist() if name.lower().endswith('.pdf')]\n",
    "                if not pdf_files_in_zip:\n",
    "                    print(f\"      - [警告] 在 {os.path.basename(file_path)} 中未找到 PDF 檔案。\")\n",
    "                    return\n",
    "                with zip_ref.open(pdf_files_in_zip[0]) as source, open(dest_pdf_path, 'wb') as target: shutil.copyfileobj(source, target)\n",
    "                print(\"      - 解壓縮完成。\")\n",
    "            os.remove(file_path)\n",
    "            print(f\"      - 已刪除原始 .zip 檔案: {os.path.basename(file_path)}\")\n",
    "        except zipfile.BadZipFile: print(f\"      - [錯誤] 檔案不是一個有效的 .zip 檔案: {os.path.basename(file_path)}\")\n",
    "        except Exception as e: print(f\"      - [錯誤] 解壓縮或刪除檔案時發生錯誤: {e}\")\n",
    "\n",
    "    def _handle_alert_if_present(self) -> bool:\n",
    "        try:\n",
    "            alert = self.driver.switch_to.alert\n",
    "            print(f\"      - [處理中] 偵測到警告視窗: '{alert.text}'。\")\n",
    "            alert.accept()\n",
    "            print(\"      - 警告視窗已關閉。\")\n",
    "            return True\n",
    "        except NoAlertPresentException: return False\n",
    "\n",
    "    def _process_article_in_new_tab(self, article_url: str, article_title: str):\n",
    "        print(f\"    - 正在處理: {article_title}\")\n",
    "        self.driver.switch_to.new_window('tab')\n",
    "        self.driver.get(article_url)\n",
    "        MAX_RETRIES = 3\n",
    "        try:\n",
    "            self.wait.until(EC.element_to_be_clickable((By.XPATH, \"//a[em[text()='電子全文']]\"))).click()\n",
    "            self.wait.until(EC.element_to_be_clickable((By.XPATH, \"//img[@alt='電子全文']/following-sibling::a[@title='電子全文']\"))).click()\n",
    "            time.sleep(random.uniform(1.5, 3.0))\n",
    "            self.driver.switch_to.window(self.driver.window_handles[-1])\n",
    "            for i in range(MAX_RETRIES):\n",
    "                print(f\"      - 偵測到下載宣言頁面，嘗試 ddddocr (第 {i + 1}/{MAX_RETRIES} 次)...\")\n",
    "                try:\n",
    "                    captcha_img = self.wait.until(EC.presence_of_element_located((By.XPATH, \"//img[contains(@src, 'random_validation')]\")))\n",
    "                    captcha_text = self._solve_captcha_with_ddddocr(captcha_img)\n",
    "                    if not captcha_text:\n",
    "                        print(\"      - ddddocr 未能辨識，刷新頁面後重試...\")\n",
    "                        self.driver.refresh()\n",
    "                        time.sleep(random.uniform(2, 4))\n",
    "                        continue\n",
    "                    input_box = self.driver.find_element(By.ID, \"validinput\")\n",
    "                    input_box.clear()\n",
    "                    input_box.send_keys(captcha_text)\n",
    "                    time.sleep(random.uniform(0.5, 1.2))\n",
    "                    self.driver.find_element(By.XPATH, \"//input[@value='我同意']\").click()\n",
    "                    time.sleep(1.5)\n",
    "                    if self._handle_alert_if_present():\n",
    "                        print(\"      - 驗證碼辨識失敗，進行下一次重試...\")\n",
    "                        self.driver.refresh()\n",
    "                        time.sleep(random.uniform(2, 4))\n",
    "                        continue\n",
    "                    print(\"      - 未偵測到警告視窗，嘗試尋找最終下載連結...\")\n",
    "                    self.wait.until(EC.presence_of_element_located((By.LINK_TEXT, \"下載\"))).click()\n",
    "                    newly_downloaded_file = self._wait_for_download_complete()\n",
    "                    if newly_downloaded_file:\n",
    "                        self._log_download(article_url)\n",
    "                        sanitized_title = self._sanitize_filename(article_title)\n",
    "                        if newly_downloaded_file.lower().endswith(\".zip\"): self._unzip_and_cleanup(newly_downloaded_file, sanitized_title)\n",
    "                        elif newly_downloaded_file.lower().endswith(\".pdf\"):\n",
    "                            new_pdf_path = os.path.join(self.download_dir, f\"{sanitized_title}.pdf\")\n",
    "                            print(f\"      - 正在重新命名為: {sanitized_title}.pdf\")\n",
    "                            if os.path.exists(new_pdf_path):\n",
    "                                base, ext = os.path.splitext(new_pdf_path)\n",
    "                                new_pdf_path = f\"{base}_{int(time.time())}{ext}\"\n",
    "                            os.rename(newly_downloaded_file, new_pdf_path)\n",
    "                        return sanitized_title, article_title, article_url\n",
    "                    else:\n",
    "                        print(\"      - [警告] 點擊最終連結後，下載逾時。\")\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    print(f\"      - [警告] 在第 {i + 1} 次重試中發生預期外的錯誤: {type(e).__name__}\")\n",
    "                    if self._handle_alert_if_present(): print(\"      - 已處理意外彈窗，將刷新頁面重試...\")\n",
    "                    else: print(f\"      - 錯誤詳情: {str(e)[:100]}...\")\n",
    "                    if i < MAX_RETRIES - 1:\n",
    "                        try:\n",
    "                            self.driver.refresh()\n",
    "                            time.sleep(random.uniform(3, 5))\n",
    "                        except Exception as refresh_e:\n",
    "                            print(f\"      - [嚴重] 刷新頁面失敗: {refresh_e}\")\n",
    "                            break\n",
    "                    else: print(\"      - 已達最大重試次數，跳過此論文。\")\n",
    "        except TimeoutException: print(\"      - [提示] 此頁面未找到「電子全文」按鈕或連結，自動跳過。\")\n",
    "        except Exception as e:\n",
    "            print(f\"      - [嚴重錯誤] 處理此頁面時發生未知錯誤: {e}\")\n",
    "            self.driver.save_screenshot(f\"error_page_{int(time.time())}.png\")\n",
    "        finally:\n",
    "            if len(self.driver.window_handles) > 1: self.driver.close()\n",
    "            self.driver.switch_to.window(self.main_window_handle)\n",
    "            sleep_duration = random.uniform(*self.inter_article_sleep_range)\n",
    "            print(f\"    - 論文處理完畢，隨機休息 {sleep_duration:.1f} 秒...\")\n",
    "            time.sleep(sleep_duration)\n",
    "        return None, None, None\n",
    "\n",
    "    def run_download_process(self):\n",
    "        print(\"\\n[步驟 3] 執行下載流程...\")\n",
    "        if not self.main_window_handle: self.main_window_handle = self.driver.current_window_handle\n",
    "        page_num = self.last_crawled_page\n",
    "        while True:\n",
    "            if self.session_download_count >= self.max_downloads_per_session:\n",
    "                print(f\"\\n[!] 已達到本次執行下載上限 ({self.max_downloads_per_session} 篇)，程式將自動停止。\")\n",
    "                print(f\"[!] 目前進度已儲存，下次執行將從第 {page_num} 頁繼續。\")\n",
    "                self._log_progress(page_num)\n",
    "                break\n",
    "            print(f\"\\n--- 正在處理第 {page_num} 頁 ---\")\n",
    "            print(f\"--- 本次執行進度: {self.session_download_count}/{self.max_downloads_per_session} ---\\n\")\n",
    "            self.driver.switch_to.window(self.main_window_handle)\n",
    "            try: self.wait.until(EC.presence_of_element_located((By.ID, \"tablefmt1\")))\n",
    "            except TimeoutException:\n",
    "                print(f\"[錯誤] 第 {page_num} 頁的搜尋結果表格載入逾時，爬取結束。\")\n",
    "                break\n",
    "            article_urls_with_titles = self._parse_article_links()\n",
    "            print(f\"[*] 本頁找到 {len(article_urls_with_titles)} 篇可處理的論文連結。\")\n",
    "            for url, title in article_urls_with_titles:\n",
    "                if self.session_download_count >= self.max_downloads_per_session: break\n",
    "                normalized_url = self._normalize_url(url)\n",
    "                if not normalized_url: continue\n",
    "                if normalized_url in self.downloaded_urls:\n",
    "                    print(f\"    - [跳過] 該論文已存在於日誌中: {title}\")\n",
    "                    continue\n",
    "                self._process_article_in_new_tab(url, title)\n",
    "            self._log_progress(page_num)\n",
    "            try:\n",
    "                print(f\"\\n[-] 正在尋找「下一頁」按鈕 (目前在第 {page_num} 頁)...\")\n",
    "                next_button = self.wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'input[name=\"gonext\"][type=\"image\"]:not([src*=\"_\"])')))\n",
    "                self.driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "                page_num += 1\n",
    "                sleep_duration = random.uniform(*self.inter_page_sleep_range)\n",
    "                print(f\"[-] 翻頁成功，前往第 {page_num} 頁。為模擬真人行為，將隨機等待 {sleep_duration:.1f} 秒...\")\n",
    "                time.sleep(sleep_duration)\n",
    "            except TimeoutException:\n",
    "                print(\"\\n[-] 未找到可點擊的「下一頁」按鈕，可能已達最後一頁。爬取結束。\")\n",
    "                if self.total_pages > 0 and page_num >= self.total_pages: print(f\"--- 已成功爬取所有 {self.total_pages} 頁論文。 ---\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"\\n[錯誤] 翻頁時發生未知錯誤: {e}。爬取結束。\")\n",
    "                break\n",
    "\n",
    "    def run(self):\n",
    "        try:\n",
    "            self._setup_driver()\n",
    "            self.wait_for_manual_login()\n",
    "            self.run_search()\n",
    "            self.run_download_process()\n",
    "        except Exception as e:\n",
    "            print(f\"\\n[主程式發生嚴重錯誤]：{type(e).__name__} - {e}\")\n",
    "            if self.driver: self.driver.save_screenshot(\"fatal_error_screenshot.png\")\n",
    "        finally:\n",
    "            self.close()\n",
    "            print(\"\\n--- 爬蟲程式執行完畢 ---\\n\")\n",
    "\n",
    "    def close(self):\n",
    "        if self.driver:\n",
    "            print(\"\\n[-] 關閉 Selenium 瀏覽器。\")\n",
    "            self.driver.quit()\n",
    "            self.driver = None\n",
    "\n",
    "class ThesisDownloaderWithReadme(BaseThesisDownloader):\n",
    "    \"\"\"\n",
    "    增強型臺灣博碩士論文網自動下載器 (v6)。\n",
    "    兼具「事後統整」與「即時記錄」兩種模式。\n",
    "    1. 啟動時，掃描資料夾，將已存在的 PDF 建立基本連結。\n",
    "    2. 下載時，即時記錄新下載的 PDF，並包含完整資訊。\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.readme_file = os.path.join(BASE_DIR, \"README.md\")\n",
    "        self.readme_handle = None\n",
    "\n",
    "    def _initialize_readme(self):\n",
    "        try:\n",
    "            print(f\"[*] 初始化 README.md 記錄檔於: {self.readme_file}\")\n",
    "            self.readme_handle = open(self.readme_file, 'a+', encoding='utf-8')\n",
    "            self.readme_handle.seek(0)\n",
    "            if not self.readme_handle.read(1):\n",
    "                session_header = (\n",
    "                    f\"# --- Crawler Session Started: {time.strftime('%Y-%m-%d %H:%M:%S')} ---\\n\"\n",
    "                    f\"**Keyword:** `{self.keyword}`\\n\\n\"\n",
    "                )\n",
    "                self.readme_handle.write(session_header)\n",
    "                self.readme_handle.flush()\n",
    "            self.readme_handle.seek(0, 2) # Move to the end for appending\n",
    "        except Exception as e:\n",
    "            print(f\"[錯誤] 初始化 README.md 失敗: {e}\")\n",
    "            self.readme_handle = None\n",
    "\n",
    "    # ==============================================================================\n",
    "    # ★★★★★★★★★★★★★★★★★★★★★★★★★ 新增的函式 ★★★★★★★★★★★★★★★★★★★★★★★★★\n",
    "    # ==============================================================================\n",
    "    def _consolidate_existing_pdfs(self):\n",
    "        \"\"\"\n",
    "        [事後統整] 掃描下載資料夾，將尚未被記錄的 PDF 檔案以基本格式加入 README.md。\n",
    "        \"\"\"\n",
    "        print(\"\\n[統整模式] 正在檢查已存在的 PDF 檔案...\")\n",
    "        if not self.readme_handle:\n",
    "            print(\"[警告] README 控制代碼未初始化，跳過統整。\")\n",
    "            return\n",
    "        if not os.path.isdir(self.download_dir):\n",
    "            print(f\"[*] 下載資料夾 '{self.download_dir}' 不存在，無需統整。\")\n",
    "            return\n",
    "\n",
    "        # 1. 讀取 README 中已記錄的檔名，避免重複加入\n",
    "        self.readme_handle.seek(0)\n",
    "        logged_pdfs = set(re.findall( r\"\\[(.*?.pdf)\\]\", self.readme_handle.read()))\n",
    "        \n",
    "        self.readme_handle.seek(0, 2) # 讀取完畢後，將指標移回檔案末尾以供後續附加\n",
    "        print(f\"[*] README 中已記錄 {len(logged_pdfs)} 個檔案。\")\n",
    "\n",
    "        # 2. 獲取資料夾中實際存在的所有 PDF 檔名\n",
    "        try:\n",
    "            existing_pdfs = {f for f in os.listdir(self.download_dir) if f.lower().endswith('.pdf')}\n",
    "        except Exception as e:\n",
    "            print(f\"[錯誤] 無法讀取下載資料夾 '{self.download_dir}': {e}\")\n",
    "            return\n",
    "\n",
    "        # 3. 找出那些存在於資料夾、但未被記錄在 README 的檔案\n",
    "        pdfs_to_add = sorted(list(existing_pdfs - logged_pdfs))\n",
    "\n",
    "        if not pdfs_to_add:\n",
    "            print(\"[*] 無需統整，所有已存在的 PDF 都已被記錄。\")\n",
    "            return\n",
    "\n",
    "        print(f\"[*] 發現 {len(pdfs_to_add)} 個尚未記錄的 PDF，現在開始寫入 README...\")\n",
    "        \n",
    "        # 4. 將新發現的檔案寫入 README\n",
    "        try:\n",
    "            self.readme_handle.write(\"\\n## --- 本次啟動時發現的已存在檔案 ---\\n\\n\")\n",
    "            for pdf_filename in pdfs_to_add:\n",
    "                encoded_filename = quote(pdf_filename)\n",
    "                pdf_relative_url = f\"./{os.path.basename(self.download_dir)}/{encoded_filename}\"\n",
    "                # 採用精簡格式，因為沒有來源網址等詳細資訊\n",
    "                readme_entry = f\"* [{pdf_filename}]({pdf_relative_url}) - `(已存在於資料夾中的檔案)`\\n\"\n",
    "                self.readme_handle.write(readme_entry)\n",
    "            \n",
    "            self.readme_handle.write(\"\\n---\\n\")\n",
    "            self.readme_handle.flush()\n",
    "            print(f\"[*] 統整完成，已將 {len(pdfs_to_add)} 個檔案連結加入 README.md。\")\n",
    "        except Exception as e:\n",
    "            print(f\"[錯誤] 寫入統整資訊到 README 時發生錯誤: {e}\")\n",
    "\n",
    "\n",
    "    def _log_readme_entry(self, sanitized_title: str, original_title: str, article_url: str):\n",
    "        \"\"\"\n",
    "        [即時記錄] 將一筆成功的下載紀錄以 Markdown 格式寫入 README.md。\n",
    "        \"\"\"\n",
    "        if self.readme_handle:\n",
    "            try:\n",
    "                pdf_filename = f\"{sanitized_title}.pdf\"\n",
    "                encoded_filename = quote(pdf_filename)\n",
    "                pdf_relative_url = f\"./{os.path.basename(self.download_dir)}/{encoded_filename}\"\n",
    "                readme_entry = (\n",
    "                    f\"* [{pdf_filename}]({pdf_relative_url}) - {original_title} \"\n",
    "                    f\"([Source]({article_url}))\\n\"\n",
    "                )\n",
    "                self.readme_handle.write(readme_entry)\n",
    "                self.readme_handle.flush()\n",
    "            except Exception as e:\n",
    "                print(f\"      - [警告] 寫入 README.md 失敗: {e}\")\n",
    "\n",
    "    def _setup_driver(self):\n",
    "        super()._setup_driver()\n",
    "        self._initialize_readme()\n",
    "\n",
    "    # ==============================================================================\n",
    "    # ★★★★★★★★★★★★★★★★★★★★★★★★★ 修改的函式 ★★★★★★★★★★★★★★★★★★★★★★★★★\n",
    "    # ==============================================================================\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        覆寫後的執行流程：\n",
    "        1. 執行基礎設定 (setup)\n",
    "        2. (新功能) 統整已存在的 PDF 檔案\n",
    "        3. 執行完整的下載流程 (登入、搜尋、下載)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # 基礎設定，會同時初始化 README.md 控制代碼\n",
    "            self._setup_driver()\n",
    "            \n",
    "            # 執行「事後統整」\n",
    "            self._consolidate_existing_pdfs()\n",
    "            \n",
    "            # 執行「即時記錄」流程\n",
    "            self.wait_for_manual_login()\n",
    "            self.run_search()\n",
    "            self.run_download_process()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n[主程式發生嚴重錯誤]：{type(e).__name__} - {e}\")\n",
    "            if self.driver:\n",
    "                self.driver.save_screenshot(\"fatal_error_screenshot.png\")\n",
    "        finally:\n",
    "            self.close()\n",
    "            print(\"\\n--- 爬蟲程式執行完畢 ---\\n\")\n",
    "\n",
    "    def close(self):\n",
    "        if self.readme_handle:\n",
    "            print(\"[-] 正在關閉 README.md 檔案...\")\n",
    "            self.readme_handle.close()\n",
    "        super().close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    SEARCH_KEYWORD = \"台股\"\n",
    "    DOWNLOAD_LIMIT = 1000\n",
    "    LONG_ARTICLE_DELAY = (15.0, 30.0)\n",
    "    LONG_PAGE_DELAY = (30.0, 60.0)\n",
    "\n",
    "    downloader = ThesisDownloaderWithReadme(\n",
    "        keyword=SEARCH_KEYWORD,\n",
    "        max_downloads_per_session=DOWNLOAD_LIMIT,\n",
    "        inter_article_sleep_range=LONG_ARTICLE_DELAY,\n",
    "        inter_page_sleep_range=LONG_PAGE_DELAY\n",
    "    )\n",
    "    downloader.run()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FINLAB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
